{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2836d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the variables, classes and functions we defined in the previous lessons\n",
    "from vars.week3 import *\n",
    "from vars.week4 import *\n",
    "from vars.week5 import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a190c130",
   "metadata": {},
   "source": [
    "# 6. More complex modules\n",
    "\n",
    "## 6.1 Subclassing nn.Module\n",
    "So far, we've looked at how to put together simple models using Pytorch's `nn.Sequential` function. Remember, all it does is sequentially line up the layers and directs the output of one into the input of the next. However, there are cases where we don't want out data to flow in such a linear fashion. A good example is a Residual Network or ResNet, which applies shortcuts between its layers. This cannot be done using a simple `nn.Sequential` construction. In such cases, it becomes necessary to sub-class the `nn.Module` class and create our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "841b1eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 14, 14]           3,200\n",
      "         MaxPool2d-2             [-1, 64, 7, 7]               0\n",
      "       BatchNorm2d-3             [-1, 64, 7, 7]             128\n",
      "              ReLU-4             [-1, 64, 7, 7]               0\n",
      "            Conv2d-5             [-1, 64, 7, 7]          36,928\n",
      "       BatchNorm2d-6             [-1, 64, 7, 7]             128\n",
      "            Conv2d-7             [-1, 64, 7, 7]          36,928\n",
      "       BatchNorm2d-8             [-1, 64, 7, 7]             128\n",
      "          ResBlock-9             [-1, 64, 7, 7]               0\n",
      "           Conv2d-10             [-1, 64, 7, 7]          36,928\n",
      "      BatchNorm2d-11             [-1, 64, 7, 7]             128\n",
      "           Conv2d-12             [-1, 64, 7, 7]          36,928\n",
      "      BatchNorm2d-13             [-1, 64, 7, 7]             128\n",
      "         ResBlock-14             [-1, 64, 7, 7]               0\n",
      "           Conv2d-15            [-1, 128, 4, 4]           8,320\n",
      "      BatchNorm2d-16            [-1, 128, 4, 4]             256\n",
      "           Conv2d-17            [-1, 128, 4, 4]          73,856\n",
      "      BatchNorm2d-18            [-1, 128, 4, 4]             256\n",
      "           Conv2d-19            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "         ResBlock-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "         ResBlock-26            [-1, 128, 4, 4]               0\n",
      "           Conv2d-27            [-1, 256, 2, 2]          33,024\n",
      "      BatchNorm2d-28            [-1, 256, 2, 2]             512\n",
      "           Conv2d-29            [-1, 256, 2, 2]         295,168\n",
      "      BatchNorm2d-30            [-1, 256, 2, 2]             512\n",
      "           Conv2d-31            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-32            [-1, 256, 2, 2]             512\n",
      "         ResBlock-33            [-1, 256, 2, 2]               0\n",
      "           Conv2d-34            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-35            [-1, 256, 2, 2]             512\n",
      "           Conv2d-36            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-37            [-1, 256, 2, 2]             512\n",
      "         ResBlock-38            [-1, 256, 2, 2]               0\n",
      "           Conv2d-39            [-1, 512, 1, 1]         131,584\n",
      "      BatchNorm2d-40            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-41            [-1, 512, 1, 1]       1,180,160\n",
      "      BatchNorm2d-42            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-43            [-1, 512, 1, 1]       2,359,808\n",
      "      BatchNorm2d-44            [-1, 512, 1, 1]           1,024\n",
      "         ResBlock-45            [-1, 512, 1, 1]               0\n",
      "           Conv2d-46            [-1, 512, 1, 1]       2,359,808\n",
      "      BatchNorm2d-47            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-48            [-1, 512, 1, 1]       2,359,808\n",
      "      BatchNorm2d-49            [-1, 512, 1, 1]           1,024\n",
      "         ResBlock-50            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-51            [-1, 512, 1, 1]               0\n",
      "          Flatten-52                  [-1, 512]               0\n",
      "           Linear-53                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,180,170\n",
      "Trainable params: 11,180,170\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.74\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 43.39\n",
      "----------------------------------------------------------------\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample):\n",
    "        super().__init__()\n",
    "        if downsample:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        shortcut = self.shortcut(inp)\n",
    "        inp = nn.ReLU()(self.bn1(self.conv1(inp)))\n",
    "        inp = nn.ReLU()(self.bn2(self.conv2(inp)))\n",
    "        inp = inp + shortcut  # The magic bit that cannot be done with nn.Sequential!\n",
    "        return nn.ReLU()(inp)\n",
    "    \n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, resblock, outputs):\n",
    "        super().__init__()\n",
    "        self.layer0_conv = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.layer0_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer0_bn   = nn.BatchNorm2d(64)\n",
    "        self.layer0_relu = nn.ReLU()\n",
    "\n",
    "        self.layer1_res1 = resblock(64, 64, downsample=False)\n",
    "        self.layer1_res2 = resblock(64, 64, downsample=False)\n",
    "\n",
    "        self.layer2_res1 = resblock(64, 128, downsample=True)\n",
    "        self.layer2_res2 = resblock(128, 128, downsample=False)\n",
    "\n",
    "        self.layer3_res1 = resblock(128, 256, downsample=True)\n",
    "        self.layer3_res2 = resblock(256, 256, downsample=False)\n",
    "\n",
    "        self.layer4_res1 = resblock(256, 512, downsample=True)\n",
    "        self.layer4_res2 = resblock(512, 512, downsample=False)\n",
    "\n",
    "        self.gap         = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flat        = nn.Flatten() \n",
    "        self.fc          = nn.Linear(512, outputs)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp = self.layer0_conv(inp)\n",
    "        inp = self.layer0_pool(inp)\n",
    "        inp = self.layer0_bn(inp)\n",
    "        inp = self.layer0_relu(inp)\n",
    "        \n",
    "        inp = self.layer1_res1(inp)\n",
    "        inp = self.layer1_res2(inp)\n",
    "        \n",
    "        inp = self.layer2_res1(inp)\n",
    "        inp = self.layer2_res2(inp)\n",
    "        \n",
    "        inp = self.layer3_res1(inp)\n",
    "        inp = self.layer3_res2(inp)\n",
    "        \n",
    "        inp = self.layer4_res1(inp)\n",
    "        inp = self.layer4_res2(inp)\n",
    "            \n",
    "        inp = self.gap(inp)\n",
    "        inp = self.flat(inp)\n",
    "        inp = self.fc(inp)\n",
    "\n",
    "        return inp\n",
    "    \n",
    "\n",
    "# convenience function\n",
    "def get_resnet():\n",
    "    return ResNet(1, ResBlock, outputs=10)\n",
    "\n",
    "\n",
    "# Print model summary\n",
    "summary(get_resnet(), input_size=(1, 28, 28), device=\"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffdbdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch[1/5], MiniBatch[390/394], Loss: 0.12823, Acc: 91.81090, LR: 0.00500\n",
      "Eval epoch[1/5], MiniBatch[260/263], Loss: 0.02793, Acc: 97.31971              \n",
      "Train epoch[2/5], MiniBatch[390/394], Loss: 0.03544, Acc: 98.36538, LR: 0.00250\n",
      "Eval epoch[2/5], MiniBatch[260/263], Loss: 0.01650, Acc: 97.82452              \n",
      "Train epoch[3/5], MiniBatch[390/394], Loss: 0.14043, Acc: 99.39904, LR: 0.00125\n",
      "Eval epoch[3/5], MiniBatch[260/263], Loss: 0.01108, Acc: 98.04087              \n",
      "Train epoch[4/5], MiniBatch[390/394], Loss: 0.00448, Acc: 99.74359, LR: 0.00063\n",
      "Eval epoch[4/5], MiniBatch[260/263], Loss: 0.03717, Acc: 98.08894              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f1098286fc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/s5602288/miniconda3/envs/sem-deep-learning/lib/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch[5/5], MiniBatch[390/394], Loss: 0.00369, Acc: 99.82372, LR: 0.00031\n",
      "Eval epoch[5/5], MiniBatch[260/263], Loss: 0.22122, Acc: 98.00481              \n"
     ]
    }
   ],
   "source": [
    "# We do not need to define a new train function as the only changes have been to the internal\n",
    "# structure of the model, not any of its inputs or outputs, so we can keep using\n",
    "# the old one - very handy!\n",
    "\n",
    "# loading data\n",
    "train_dl, val_dl, test_dl =load_data(DATA_PATH,batch_sz=batch_sz)\n",
    "dataloaders = {\n",
    "    'train': train_dl,\n",
    "    'val': val_dl,\n",
    "    'test': test_dl\n",
    "}\n",
    "\n",
    "# Instantiate the res net\n",
    "network = get_resnet()\n",
    "# Send it to the GPU device\n",
    "network = network.to(DEVICE)\n",
    "optim = SGD(network.parameters(),lr=learning_rate)\n",
    "lr_sch = ExponentialLR(optim,gamma)\n",
    "# Call the lateset training function from last week\n",
    "train_model_gpu_lr_conv_valid(network,epochs,dataloaders,optim,lr_sch,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d305a279",
   "metadata": {},
   "source": [
    "## 6.2 Early stopping\n",
    "Model training on a typical machine learning project is a time-consuming process. Sometimes, we may even want to run the same model multiple times with different parameters to see which ones work the best (a process known as hyper-parameter tuning). If a model is allowed to run for a long time despite not getting any better at learning, that's wasted time and computing power. We use early stopping to tackle this problem. This is a simple algorithm that just says whether or not the model should be stopped, based on its performance over time. \n",
    "\n",
    "To illustrate this concept, we define a class `EarlyStopper` that performs this check. Its should_stop method must be called every epoch with the current validation accuracy for that epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2847fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, tolerance=0):\n",
    "       self.patience = patience # How many epochs in a row the model is allowed to underperform    \n",
    "       self.tolerance = tolerance # How much leeway the model has (i.e. how close it can get to underperforming before it is counted as such)\n",
    "       self.epoch_counter = 0 # Keeping track of how many epochs in a row were failed \n",
    "       self.max_validation_acc = np.NINF # Keeping track of best metric so far\n",
    "\n",
    "    def should_stop(self, validation_acc):\n",
    "        print(f\"current val max : {self.max_validation_acc} , val acc : {validation_acc}\" )\n",
    "        if validation_acc > self.max_validation_acc:\n",
    "            self.max_validation_acc = validation_acc\n",
    "            self.epoch_counter = 0\n",
    "        elif validation_acc < (self.max_validation_acc - self.tolerance):\n",
    "            self.epoch_counter += 1\n",
    "            if self.epoch_counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e758d07",
   "metadata": {},
   "source": [
    "## 6.3 Logging\n",
    "We will also be using a logging tool called `tensorboard` to keep track of our metrics and visualise the performance of our model as it goes through its training cyle. The output of a Pytorch training run is typically stored in a directory called `runs` somewhere in the project root. We need to pass this directory to `tensorboard` so that it can display the progress of our runs for us. Let's import this module now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b06783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9428863c",
   "metadata": {},
   "source": [
    "## 6.4 Checkpointing\n",
    "Finally, it is typical in machine learning pipelines to save the progress of a long-running training session every so often. Since it is such a time consuming process, chances are, sooner or later, one of any number of things outside the control of the programmer might interrupt the training (power outage, alien attack etc, etc.). If such a thing were to happen in the middle of a training cyle, that could mean days or weeks of training lost in an instant. It's STRONGLY recommended that you implement some kind of checkpointing functionality in your ML training pipeline. We define a save function below for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b412ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Saves a model to file, and names it after the current epoch\n",
    "def save_checkpoint(model, epoch, save_dir):\n",
    "    filename = f\"checkpoint_{epoch}.pth\"\n",
    "    save_path = f\"{save_dir}/{filename}\"\n",
    "    torch.save({'state_dict': model.state_dict()}, save_path)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8af23dc",
   "metadata": {},
   "source": [
    "## 6.5 Final training loop \n",
    "Using all this information, we update our training function one last time.\n",
    "\n",
    "For those of you keeping score, this training function now supports:\n",
    "1. GPU training\n",
    "2. Adaptive learning rates\n",
    "3. Training and validation epochs\n",
    "4. Early stopping\n",
    "5. Logging metrics \n",
    "6. Model checkpointing\n",
    "\n",
    "To avoid ending up with a ridiculously long name for our training function (`train_model_gpu_lr_conv_valid_stopping_logging_checkpoint` or some such), we shall rename it one last time to something sensible. 3 additional arguments have been added: the summary writer, the early stopper that we just wrote, and how often we want to save checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c19f3703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_final(model, \n",
    "                      epochs, \n",
    "                      dataloaders, \n",
    "                      optimiser, \n",
    "                      lr_scheduler, \n",
    "                      writer, \n",
    "                      early_stopper, \n",
    "                      checkpoint_frequency):\n",
    "    msg = \"\"\n",
    "    for epoch in range(epochs):        \n",
    "        #######################TRAINING STEP###################################\n",
    "        model.train()  # set model to training mode \n",
    "        train_dl = dataloaders['train'] # select train dataloader\n",
    "        \n",
    "        total_steps_train = len(train_dl)\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        loss_train = 0\n",
    "        \n",
    "        for batch_num, (image_batch, label_batch) in enumerate(train_dl):\n",
    "            batch_sz = len(image_batch)\n",
    "            label_batch = label_batch.to(DEVICE)\n",
    "            image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28) \n",
    "            output = model(image_batch)\n",
    "            loss_train = nn.CrossEntropyLoss()(output, label_batch)\n",
    "                        \n",
    "            optimiser.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            preds_train = torch.argmax(output, dim=1)\n",
    "            correct_train += int(torch.eq(preds_train, label_batch).sum())\n",
    "            total_train += batch_sz\n",
    "            minibatch_accuracy_train = 100 * correct_train / total_train\n",
    "            \n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "            if (batch_num + 1) % 5 == 0:\n",
    "                print(\" \" * len(msg), end='\\r')\n",
    "                msg = f'Train epoch[{epoch+1}/{epochs}], MiniBatch[{batch_num + 1}/{total_steps_train}], Loss: {loss_train.item():.5f}, Acc: {minibatch_accuracy_train:.5f}, LR: {lr_scheduler.get_last_lr()[0]:.5f}'\n",
    "                print (msg, end='\\r' if epoch < epochs else \"\\n\",flush=True)\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "        lr_scheduler.step()\n",
    "        ########################################################################\n",
    "        print(\"\") # Create newline between progress bars\n",
    "        #######################VALIDATION STEP##################################\n",
    "        model.eval()  # set model to evaluation mode. This is very important, we do not want to update model weights in eval mode\n",
    "        val_dl = dataloaders['val'] # select val dataloader\n",
    "        \n",
    "        total_steps_val = len(val_dl)\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        loss_val = 0\n",
    "        \n",
    "        for batch_num, (image_batch, label_batch) in enumerate(val_dl):\n",
    "            batch_sz = len(image_batch)\n",
    "            label_batch = label_batch.to(DEVICE)\n",
    "            image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28) \n",
    "            \n",
    "            with torch.no_grad(): # no_grad disables gradient calculations, which are not needed when evaluating the model. This speeds up the calculations\n",
    "                output = model(image_batch)\n",
    "                loss_val = nn.CrossEntropyLoss()(output, label_batch)\n",
    "\n",
    "                preds_val = torch.argmax(output, dim=1)\n",
    "                correct_val += int(torch.eq(preds_val, label_batch).sum())\n",
    "                total_val += batch_sz\n",
    "                minibatch_accuracy_val = 100 * correct_val / total_val\n",
    "                \n",
    "                #### Fancy printing stuff, you can ignore this! ######\n",
    "                if (batch_num + 1) % 5 == 0:\n",
    "                    print(\" \" * len(msg), end='\\r')\n",
    "                    msg = f'Eval epoch[{epoch+1}/{epochs}], MiniBatch[{batch_num + 1}/{total_steps_val}], Loss: {loss_val.item():.5f}, Acc: {minibatch_accuracy_val:.5f}'\n",
    "                    if early_stopper.epoch_counter > 0:\n",
    "                        msg += f\", Epochs without improvement: {early_stopper.epoch_counter}\"\n",
    "                    print (msg, end='\\r' if epoch < epochs else \"\\n\",flush=True)\n",
    "                #### Fancy printing stuff, you can ignore this! ######\n",
    "        ########################################################################\n",
    "        print(\"\")  # Create newline between progress bars\n",
    "        \n",
    "        epoch_train_acc = 100*correct_train/total_train\n",
    "        epoch_val_acc = 100* correct_val/total_val\n",
    "        \n",
    "        writer.add_scalar('Loss/train',loss_train,epoch)\n",
    "        writer.add_scalar('Loss/val',loss_val,epoch)\n",
    "        \n",
    "        writer.add_scalar('Accuracy/train',epoch_train_acc,epoch)\n",
    "        writer.add_scalar('Accuracy/train',epoch_val_acc,epoch)\n",
    "        # Log loss and accuracy metrics using the writer so we can see them in Tensorboard \n",
    "        # Check whether we need to save the model to a checkpoint file\n",
    "        if epoch % checkpoint_frequency == 0:\n",
    "            save_checkpoint(model,epoch, \"./Saved_models\")\n",
    "        # Check whether we should stop the training based on the validation accuracy\n",
    "        if early_stopper.should_stop(epoch_val_acc):\n",
    "            print(f\"\\nvalidation accuracy has not improved in {early_stopper.epoch_counter} epoch, stopping.\")\n",
    "            # if stopping, we also want to save the model's state\n",
    "            save_checkpoint(model,epoch,\"./Saved_models\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66091303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch[1/15], MiniBatch[95/99], Loss: 0.14316, Acc: 88.20724, LR: 0.00500\n",
      "Eval epoch[1/15], MiniBatch[65/66], Loss: 0.21333, Acc: 94.97596              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m stopper \u001b[39m=\u001b[39m EarlyStopper(patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,tolerance\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m#stop traning if the model accuracy is not getting better that the max so far\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m# Call train_model_final on these arguments\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m train_model_final(model\u001b[39m=\u001b[39;49m network, \n\u001b[1;32m     28\u001b[0m                       epochs\u001b[39m=\u001b[39;49m epochs, \n\u001b[1;32m     29\u001b[0m                       dataloaders\u001b[39m=\u001b[39;49m dataloaders, \n\u001b[1;32m     30\u001b[0m                       optimiser\u001b[39m=\u001b[39;49m optim, \n\u001b[1;32m     31\u001b[0m                       lr_scheduler \u001b[39m=\u001b[39;49m lr_sch, \n\u001b[1;32m     32\u001b[0m                       writer \u001b[39m=\u001b[39;49m writer, \n\u001b[1;32m     33\u001b[0m                       early_stopper \u001b[39m=\u001b[39;49m stopper, \n\u001b[1;32m     34\u001b[0m                       checkpoint_frequency \u001b[39m=\u001b[39;49m checkpoint_frequency)\n",
      "Cell \u001b[0;32mIn[12], line 54\u001b[0m, in \u001b[0;36mtrain_model_final\u001b[0;34m(model, epochs, dataloaders, optimiser, lr_scheduler, writer, early_stopper, checkpoint_frequency)\u001b[0m\n\u001b[1;32m     51\u001b[0m total_val \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     52\u001b[0m loss_val \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 54\u001b[0m \u001b[39mfor\u001b[39;49;00m batch_num, (image_batch, label_batch) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(val_dl):\n\u001b[1;32m     55\u001b[0m     batch_sz \u001b[39m=\u001b[39;49m \u001b[39mlen\u001b[39;49m(image_batch)\n\u001b[1;32m     56\u001b[0m     label_batch \u001b[39m=\u001b[39;49m label_batch\u001b[39m.\u001b[39;49mto(DEVICE)\n",
      "File \u001b[0;32m~/miniconda3/envs/sem-deep-learning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/sem-deep-learning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1317\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1317\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \n\u001b[1;32m   1322\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sem-deep-learning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1442\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1438\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1439\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1443\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1444\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/miniconda3/envs/sem-deep-learning/lib/python3.11/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sem-deep-learning/lib/python3.11/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinel], timeout):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sem-deep-learning/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    929\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    931\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    932\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/sem-deep-learning/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selector\u001b[39m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Putting it all together now, we can launch the final training run!\n",
    "epochs =   15            # increase epochs to show off early stopper\n",
    "batch_sz = 128           # increase batch size for faster processing on GPU\n",
    "checkpoint_frequency = 3 # save model to a file every 3 epochs  \n",
    "\n",
    "\n",
    "# data loading with new batch size\n",
    "train_dl, val_dl, test_dl = load_data(DATA_PATH,batch_sz=batch_sz)\n",
    "dataloaders = {\n",
    "    'train': train_dl,\n",
    "    'val': val_dl,\n",
    "    'test': test_dl\n",
    "}\n",
    "\n",
    "# Instatiate network and send to device\n",
    "network = get_resnet()\n",
    "network = network.to(DEVICE)\n",
    "# Get SGD optimiser and lr scheduler\n",
    "optim = SGD(network.parameters(),lr=learning_rate)\n",
    "lr_sch =  ExponentialLR(optim,gamma)\n",
    "\n",
    "# Instantiate summary writer\n",
    "writer = SummaryWriter()\n",
    "# Instantiate early stopper with patience=3 and tolerance=0\n",
    "stopper = EarlyStopper(patience=3,tolerance=0) #stop traning if the model accuracy is not getting better that the max so far\n",
    "# Call train_model_final on these arguments\n",
    "train_model_final(model= network, \n",
    "                      epochs= epochs, \n",
    "                      dataloaders= dataloaders, \n",
    "                      optimiser= optim, \n",
    "                      lr_scheduler = lr_sch, \n",
    "                      writer = writer, \n",
    "                      early_stopper = stopper, \n",
    "                      checkpoint_frequency = checkpoint_frequency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6f345b0",
   "metadata": {},
   "source": [
    "## 6.6 Deployment\n",
    "Once you're happy with your trained model, you can load it from the latest checkpoint that has been saved. The exact number will depend on when your training was stopped so please check this in your `saved_models` directory before loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8769390",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 14\n",
    "loaded_net_state_dict = torch.load(f\"./Saved_models/checkpoint_{last_epoch}.pth\")[\"state_dict\"]\n",
    "train_dl, val_dl, test_dl = load_data(DATA_PATH, batch_sz=batch_sz)\n",
    "dataloaders = {\n",
    "    'train': train_dl,\n",
    "    'val': val_dl,\n",
    "    'test': test_dl\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0acd99ab",
   "metadata": {},
   "source": [
    "## 6.7 Testing/Inference\n",
    "Congratulations! This is the point at which you've trained your model to your satisfaction and are ready to throw it into some real world applications. We can now use the test data split that we've been hanging onto for ages to see how the model does against it. First, we define a testing function (this is identical to the validation routine in our training function. We're just using this as a substitute for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba003979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    test_dl = dataloaders['test']\n",
    "    total_steps = len(test_dl)\n",
    "    msg = \"\"\n",
    "    for batch_num, (image_batch, label_batch) in enumerate(test_dl):\n",
    "        batch_sz = len(image_batch)\n",
    "        label_batch = label_batch.to(DEVICE)\n",
    "        image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28)\n",
    "        out = model(image_batch)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        correct += int(torch.eq(preds, label_batch).sum())\n",
    "        total += label_batch.shape[0]\n",
    "        if (batch_num + 1) % 5 == 0:\n",
    "            print(\" \" * len(msg), end='\\r')\n",
    "            msg = f'Testing batch[{batch_num + 1}/{total_steps}]'\n",
    "            print (msg, end='\\r' if batch_num < total_steps else \"\\n\", flush=True)\n",
    "    print(f\"\\nFinal test accuracy for {total} examples: {100 * correct/total:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0deab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_resnet()\n",
    "model.to(DEVICE)\n",
    "model.load_state_dict(loaded_net_state_dict)\n",
    "test_model(model, dataloaders)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ac58f42",
   "metadata": {},
   "source": [
    "# 6.8 Pytorch Lightning\n",
    "Pytorch lightning is a framework that further simplifies the process of building a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8c5e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc5307ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlResNet(pl.LightningModule):\n",
    "    def __init__(self, in_channels, outputs):\n",
    "        super().__init__()\n",
    "        # model arch goes here\n",
    "        self.model = ResNet(in_channels, ResBlock , outputs)\n",
    "    def forward(self, inp):\n",
    "        return self.model.forward(inp)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return SGD(self.parameters(),lr=learning_rate)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        image_batch, label_batch  = batch\n",
    "        batch_sz = len(image_batch)\n",
    "        #label_batch = label_batch.to(DEVICE)\n",
    "        #image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28)\n",
    "        label_batch = label_batch\n",
    "        image_batch = image_batch.reshape(batch_sz, 1, 28, 28)\n",
    "        output = model(image_batch)\n",
    "        loss = nn.CrossEntropyLoss()(output, label_batch)\n",
    "\n",
    "        preds_train = torch.argmax(output, dim=1)\n",
    "        correct_train = int(torch.eq(preds_train,label_batch).sum())\n",
    "        minibatch_accuracy_train = 100*correct_train / batch_sz\n",
    "\n",
    "        self.log(\"train_acc\",minibatch_accuracy_train)\n",
    "        self.log(\"train_loss\",loss)\n",
    "\n",
    "        \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        image_batch,label_batch = batch\n",
    "        batch_sz = len(image_batch)\n",
    "        #label_batch = label_batch.to(DEVICE)\n",
    "        #image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28)\n",
    "        label_batch = label_batch\n",
    "        image_batch = image_batch.reshape(batch_sz, 1, 28, 28)\n",
    "        output = model(image_batch)\n",
    "        loss = nn.CrossEntropyLoss()(output, label_batch)\n",
    "\n",
    "\n",
    "        preds_val = torch.argmax(output, dim=1)\n",
    "        correct_val = int(torch.eq(preds_val,label_batch).sum())\n",
    "        minibatch_accuracy_val = 100*correct_val / batch_sz\n",
    "\n",
    "        self.log(\"val_acc\",minibatch_accuracy_val)\n",
    "        self.log(\"val_loss\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15cccfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_dl, val_dl, test_dl = load_data(DATA_PATH, batch_sz=batch_sz)\n",
    "\n",
    "# Instantiate PlResNet with the appropriate inputs and outputs\n",
    "model = PlResNet(in_channels=1,outputs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d7eaa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "097fa2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s5602288/miniconda3/envs/sem-deep-learning/lib/python3.11/site-packages/lightning_fabric/connector.py:565: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/s5602288/miniconda3/envs/sem-deep-learning/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/s5602288/miniconda3/envs/sem-deep-learning/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory ./Saved_models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.2 M\n",
      "---------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.721    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s5602288/miniconda3/envs/sem-deep-learning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  41%|████▏     | 41/99 [00:00<00:00, 126.24it/s, v_num=6]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s5602288/miniconda3/envs/sem-deep-learning/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 99/99 [00:03<00:00, 28.83it/s, v_num=6] \n"
     ]
    }
   ],
   "source": [
    "# define callbacks\n",
    "# saves last-K checkpoints based on \"global_step\" metric\n",
    "# make sure you log it inside your LightningModule\n",
    "# NOTE: Talk a little bit about what callback functions are\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=5,\n",
    "    monitor='val_loss',  # 'val_acc' or 'val_loss'\n",
    "    mode='min',           # one of {auto, min, max}\n",
    "    dirpath= './Saved_models',\n",
    "    filename= \"mnist_nodel_{epoch:02d}\"\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_acc\",\n",
    "    mode='max',\n",
    "    patience=3,\n",
    "    min_delta=0.0\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer(accelerator='gpu',\n",
    "                     precision=16,\n",
    "                     devices=1,\n",
    "                     callbacks=[early_stop_callback,checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dl,val_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
