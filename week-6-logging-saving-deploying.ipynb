{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2836d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the variables, classes and functions we defined in the previous lessons\n",
    "from vars.week3 import *\n",
    "from vars.week4 import *\n",
    "from vars.week5 import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a190c130",
   "metadata": {},
   "source": [
    "# 6. More complex modules\n",
    "\n",
    "## 6.1 Subclassing nn.Module\n",
    "So far, we've looked at how to put together simple models using Pytorch's `nn.Sequential` function. Remember, all it does is sequentially line up the layers and directs the output of one into the input of the next. However, there are cases where we don't want out data to flow in such a linear fashion. A good example is a Residual Network or ResNet, which applies shortcuts between its layers. This cannot be done using a simple `nn.Sequential` construction. In such cases, it becomes necessary to sub-class the `nn.Module` class and create our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample):\n",
    "        super().__init__()\n",
    "        if downsample:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        shortcut = self.shortcut(inp)\n",
    "        inp = nn.ReLU()(self.bn1(self.conv1(inp)))\n",
    "        inp = nn.ReLU()(self.bn2(self.conv2(inp)))\n",
    "        inp = inp + shortcut  # The magic bit that cannot be done with nn.Sequential!\n",
    "        return nn.ReLU()(inp)\n",
    "    \n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, resblock, outputs):\n",
    "        super().__init__()\n",
    "        self.layer0_conv = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.layer0_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer0_bn   = nn.BatchNorm2d(64)\n",
    "        self.layer0_relu = nn.ReLU()\n",
    "\n",
    "        self.layer1_res1 = resblock(64, 64, downsample=False)\n",
    "        self.layer1_res2 = resblock(64, 64, downsample=False)\n",
    "\n",
    "        self.layer2_res1 = resblock(64, 128, downsample=True)\n",
    "        self.layer2_res2 = resblock(128, 128, downsample=False)\n",
    "\n",
    "        self.layer3_res1 = resblock(128, 256, downsample=True)\n",
    "        self.layer3_res2 = resblock(256, 256, downsample=False)\n",
    "\n",
    "        self.layer4_res1 = resblock(256, 512, downsample=True)\n",
    "        self.layer4_res2 = resblock(512, 512, downsample=False)\n",
    "\n",
    "        self.gap         = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flat        = nn.Flatten() \n",
    "        self.fc          = nn.Linear(512, outputs)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp = self.layer0_conv(inp)\n",
    "        inp = self.layer0_pool(inp)\n",
    "        inp = self.layer0_bn(inp)\n",
    "        inp = self.layer0_relu(inp)\n",
    "        \n",
    "        inp = self.layer1_res1(inp)\n",
    "        inp = self.layer1_res2(inp)\n",
    "        \n",
    "        inp = self.layer2_res1(inp)\n",
    "        inp = self.layer2_res2(inp)\n",
    "        \n",
    "        inp = self.layer3_res1(inp)\n",
    "        inp = self.layer3_res2(inp)\n",
    "        \n",
    "        inp = self.layer4_res1(inp)\n",
    "        inp = self.layer4_res2(inp)\n",
    "            \n",
    "        inp = self.gap(inp)\n",
    "        inp = self.flat(inp)\n",
    "        inp = self.fc(inp)\n",
    "\n",
    "        return inp\n",
    "    \n",
    "\n",
    "# convenience function\n",
    "def get_resnet():\n",
    "    return ResNet(1, ResBlock, outputs=10)\n",
    "\n",
    "\n",
    "# Print model summary\n",
    "summary(get_resnet(), input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdbdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not need to define a new train function as the only changes have been to the internal\n",
    "# structure of the model, not any of its inputs or outputs, so we can keep using\n",
    "# the old one - very handy!\n",
    "\n",
    "# loading data\n",
    "train_dl, val_dl, test_dl =load_data(DATA_PATH,batch_sz=batch_sz)\n",
    "dataloaders = {\n",
    "    'train': train_dl,\n",
    "    'val': val_dl,\n",
    "    'test': test_dl\n",
    "}\n",
    "\n",
    "# Instantiate the res net\n",
    "network = get_resnet()\n",
    "# Send it to the GPU device\n",
    "network = network.to(DEVICE)\n",
    "optim = SGD(network.parameters(),lr=learning_rate)\n",
    "lr_sch = ExponentialLR(optim,gamma)\n",
    "# Call the lateset training function from last week\n",
    "train_model_gpu_lr_conv_valid(network,epochs,dataloaders,optim,lr_sch,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d305a279",
   "metadata": {},
   "source": [
    "## 6.2 Early stopping\n",
    "Model training on a typical machine learning project is a time-consuming process. Sometimes, we may even want to run the same model multiple times with different parameters to see which ones work the best (a process known as hyper-parameter tuning). If a model is allowed to run for a long time despite not getting any better at learning, that's wasted time and computing power. We use early stopping to tackle this problem. This is a simple algorithm that just says whether or not the model should be stopped, based on its performance over time. \n",
    "\n",
    "To illustrate this concept, we define a class `EarlyStopper` that performs this check. Its should_stop method must be called every epoch with the current validation accuracy for that epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, tolerance=0):\n",
    "       self.patience = patience # How many epochs in a row the model is allowed to underperform    \n",
    "       self.tolerance = tolerance # How much leeway the model has (i.e. how close it can get to underperforming before it is counted as such)\n",
    "       self.epoch_counter = 0 # Keeping track of how many epochs in a row were failed \n",
    "       self.max_validation_acc = np.NINF # Keeping track of best metric so far\n",
    "\n",
    "    def should_stop(self, validation_acc):\n",
    "        print(f\"current val max : {self.max_validation_acc} , val acc : {validation_acc}\" )\n",
    "        if validation_acc > self.max_validation_acc:\n",
    "            self.max_validation_acc = validation_acc\n",
    "            self.epoch_counter = 0\n",
    "        elif validation_acc < (self.max_validation_acc - self.tolerance):\n",
    "            self.epoch_counter += 1\n",
    "            if self.epoch_counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e758d07",
   "metadata": {},
   "source": [
    "## 6.3 Logging\n",
    "We will also be using a logging tool called `tensorboard` to keep track of our metrics and visualise the performance of our model as it goes through its training cyle. The output of a Pytorch training run is typically stored in a directory called `runs` somewhere in the project root. We need to pass this directory to `tensorboard` so that it can display the progress of our runs for us. Let's import this module now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b06783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9428863c",
   "metadata": {},
   "source": [
    "## 6.4 Checkpointing\n",
    "Finally, it is typical in machine learning pipelines to save the progress of a long-running training session every so often. Since it is such a time consuming process, chances are, sooner or later, one of any number of things outside the control of the programmer might interrupt the training (power outage, alien attack etc, etc.). If such a thing were to happen in the middle of a training cyle, that could mean days or weeks of training lost in an instant. It's STRONGLY recommended that you implement some kind of checkpointing functionality in your ML training pipeline. We define a save function below for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b412ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Saves a model to file, and names it after the current epoch\n",
    "def save_checkpoint(model, epoch, save_dir):\n",
    "    filename = f\"checkpoint_{epoch}.pth\"\n",
    "    save_path = f\"{save_dir}/{filename}\"\n",
    "    torch.save({'state_dict': model.state_dict()}, save_path)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8af23dc",
   "metadata": {},
   "source": [
    "## 6.5 Final training loop \n",
    "Using all this information, we update our training function one last time.\n",
    "\n",
    "For those of you keeping score, this training function now supports:\n",
    "1. GPU training\n",
    "2. Adaptive learning rates\n",
    "3. Training and validation epochs\n",
    "4. Early stopping\n",
    "5. Logging metrics \n",
    "6. Model checkpointing\n",
    "\n",
    "To avoid ending up with a ridiculously long name for our training function (`train_model_gpu_lr_conv_valid_stopping_logging_checkpoint` or some such), we shall rename it one last time to something sensible. 3 additional arguments have been added: the summary writer, the early stopper that we just wrote, and how often we want to save checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f3703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_final(model, \n",
    "                      epochs, \n",
    "                      dataloaders, \n",
    "                      optimiser, \n",
    "                      lr_scheduler, \n",
    "                      writer, \n",
    "                      early_stopper, \n",
    "                      checkpoint_frequency):\n",
    "    msg = \"\"\n",
    "    for epoch in range(epochs):        \n",
    "        #######################TRAINING STEP###################################\n",
    "        model.train()  # set model to training mode \n",
    "        train_dl = dataloaders['train'] # select train dataloader\n",
    "        \n",
    "        total_steps_train = len(train_dl)\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        loss_train = 0\n",
    "        \n",
    "        for batch_num, (image_batch, label_batch) in enumerate(train_dl):\n",
    "            batch_sz = len(image_batch)\n",
    "            label_batch = label_batch.to(DEVICE)\n",
    "            image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28) \n",
    "            output = model(image_batch)\n",
    "            loss_train = nn.CrossEntropyLoss()(output, label_batch)\n",
    "                        \n",
    "            optimiser.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            preds_train = torch.argmax(output, dim=1)\n",
    "            correct_train += int(torch.eq(preds_train, label_batch).sum())\n",
    "            total_train += batch_sz\n",
    "            minibatch_accuracy_train = 100 * correct_train / total_train\n",
    "            \n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "            if (batch_num + 1) % 5 == 0:\n",
    "                print(\" \" * len(msg), end='\\r')\n",
    "                msg = f'Train epoch[{epoch+1}/{epochs}], MiniBatch[{batch_num + 1}/{total_steps_train}], Loss: {loss_train.item():.5f}, Acc: {minibatch_accuracy_train:.5f}, LR: {lr_scheduler.get_last_lr()[0]:.5f}'\n",
    "                print (msg, end='\\r' if epoch < epochs else \"\\n\",flush=True)\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "        lr_scheduler.step()\n",
    "        ########################################################################\n",
    "        print(\"\") # Create newline between progress bars\n",
    "        #######################VALIDATION STEP##################################\n",
    "        model.eval()  # set model to evaluation mode. This is very important, we do not want to update model weights in eval mode\n",
    "        val_dl = dataloaders['val'] # select val dataloader\n",
    "        \n",
    "        total_steps_val = len(val_dl)\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        loss_val = 0\n",
    "        \n",
    "        for batch_num, (image_batch, label_batch) in enumerate(val_dl):\n",
    "            batch_sz = len(image_batch)\n",
    "            label_batch = label_batch.to(DEVICE)\n",
    "            image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28) \n",
    "            \n",
    "            with torch.no_grad(): # no_grad disables gradient calculations, which are not needed when evaluating the model. This speeds up the calculations\n",
    "                output = model(image_batch)\n",
    "                loss_val = nn.CrossEntropyLoss()(output, label_batch)\n",
    "\n",
    "                preds_val = torch.argmax(output, dim=1)\n",
    "                correct_val += int(torch.eq(preds_val, label_batch).sum())\n",
    "                total_val += batch_sz\n",
    "                minibatch_accuracy_val = 100 * correct_val / total_val\n",
    "                \n",
    "                #### Fancy printing stuff, you can ignore this! ######\n",
    "                if (batch_num + 1) % 5 == 0:\n",
    "                    print(\" \" * len(msg), end='\\r')\n",
    "                    msg = f'Eval epoch[{epoch+1}/{epochs}], MiniBatch[{batch_num + 1}/{total_steps_val}], Loss: {loss_val.item():.5f}, Acc: {minibatch_accuracy_val:.5f}'\n",
    "                    if early_stopper.epoch_counter > 0:\n",
    "                        msg += f\", Epochs without improvement: {early_stopper.epoch_counter}\"\n",
    "                    print (msg, end='\\r' if epoch < epochs else \"\\n\",flush=True)\n",
    "                #### Fancy printing stuff, you can ignore this! ######\n",
    "        ########################################################################\n",
    "        print(\"\")  # Create newline between progress bars\n",
    "        \n",
    "        epoch_train_acc = 100*correct_train/total_train\n",
    "        epoch_val_acc = 100* correct_val/total_val\n",
    "        \n",
    "        writer.add_scalar('Loss/train',loss_train,epoch)\n",
    "        writer.add_scalar('Loss/val',loss_val,epoch)\n",
    "        \n",
    "        writer.add_scalar('Accuracy/train',epoch_train_acc,epoch)\n",
    "        writer.add_scalar('Accuracy/train',epoch_val_acc,epoch)\n",
    "        # Log loss and accuracy metrics using the writer so we can see them in Tensorboard \n",
    "        # Check whether we need to save the model to a checkpoint file\n",
    "        if epoch % checkpoint_frequency == 0:\n",
    "            save_checkpoint(model,epoch, \"./Saved_models\")\n",
    "        # Check whether we should stop the training based on the validation accuracy\n",
    "        if early_stopper.should_stop(epoch_val_acc):\n",
    "            print(f\"\\nvalidation accuracy has not improved in {early_stopper.epoch_counter} epoch, stopping.\")\n",
    "            # if stopping, we also want to save the model's state\n",
    "            save_checkpoint(model,epoch,\"./Saved_models\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66091303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it all together now, we can launch the final training run!\n",
    "epochs =   15            # increase epochs to show off early stopper\n",
    "batch_sz = 128           # increase batch size for faster processing on GPU\n",
    "checkpoint_frequency = 3 # save model to a file every 3 epochs  \n",
    "\n",
    "\n",
    "# data loading with new batch size\n",
    "train_dl, val_dl, test_dl = load_data(DATA_PATH,batch_sz=batch_sz)\n",
    "dataloaders = {\n",
    "    'train': train_dl,\n",
    "    'val': val_dl,\n",
    "    'test': test_dl\n",
    "}\n",
    "\n",
    "# Instatiate network and send to device\n",
    "network = get_resnet()\n",
    "network = network.to(DEVICE)\n",
    "# Get SGD optimiser and lr scheduler\n",
    "optim = SGD(network.parameters(),lr=learning_rate)\n",
    "lr_sch =  ExponentialLR(optim,gamma)\n",
    "\n",
    "# Instantiate summary writer\n",
    "writer = SummaryWriter()\n",
    "# Instantiate early stopper with patience=3 and tolerance=0\n",
    "stopper = EarlyStopper(patience=3,tolerance=0) #stop traning if the model accuracy is not getting better that the max so far\n",
    "# Call train_model_final on these arguments\n",
    "train_model_final(model= network, \n",
    "                      epochs= epochs, \n",
    "                      dataloaders= dataloaders, \n",
    "                      optimiser= optim, \n",
    "                      lr_scheduler = lr_sch, \n",
    "                      writer = writer, \n",
    "                      early_stopper = stopper, \n",
    "                      checkpoint_frequency = checkpoint_frequency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6f345b0",
   "metadata": {},
   "source": [
    "## 6.6 Deployment\n",
    "Once you're happy with your trained model, you can load it from the latest checkpoint that has been saved. The exact number will depend on when your training was stopped so please check this in your `saved_models` directory before loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8769390",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 14\n",
    "loaded_net_state_dict = torch.load(f\"./Saved_models/checkpoint_{last_epoch}.pth\")[\"state_dict\"]\n",
    "train_dl, val_dl, test_dl = load_data(DATA_PATH, batch_sz=batch_sz)\n",
    "dataloaders = {\n",
    "    'train': train_dl,\n",
    "    'val': val_dl,\n",
    "    'test': test_dl\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0acd99ab",
   "metadata": {},
   "source": [
    "## 6.7 Testing/Inference\n",
    "Congratulations! This is the point at which you've trained your model to your satisfaction and are ready to throw it into some real world applications. We can now use the test data split that we've been hanging onto for ages to see how the model does against it. First, we define a testing function (this is identical to the validation routine in our training function. We're just using this as a substitute for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba003979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    test_dl = dataloaders['test']\n",
    "    total_steps = len(test_dl)\n",
    "    msg = \"\"\n",
    "    for batch_num, (image_batch, label_batch) in enumerate(test_dl):\n",
    "        batch_sz = len(image_batch)\n",
    "        label_batch = label_batch.to(DEVICE)\n",
    "        image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28)\n",
    "        out = model(image_batch)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        correct += int(torch.eq(preds, label_batch).sum())\n",
    "        total += label_batch.shape[0]\n",
    "        if (batch_num + 1) % 5 == 0:\n",
    "            print(\" \" * len(msg), end='\\r')\n",
    "            msg = f'Testing batch[{batch_num + 1}/{total_steps}]'\n",
    "            print (msg, end='\\r' if batch_num < total_steps else \"\\n\", flush=True)\n",
    "    print(f\"\\nFinal test accuracy for {total} examples: {100 * correct/total:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0deab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_resnet()\n",
    "model.load_state_dict(loaded_net_state_dict)\n",
    "test_model(model, dataloaders)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ac58f42",
   "metadata": {},
   "source": [
    "# 6.8 Pytorch Lightning\n",
    "Pytorch lightning is a framework that further simplifies the process of building a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5307ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlResNet(pl.LightningModule):\n",
    "    def __init__(self, in_channels, outputs):\n",
    "        super().__init__()\n",
    "        # model arch goes here\n",
    "        self.model = ResNet(in_channels, ResBlock , outputs)\n",
    "    def forward(self, inp):\n",
    "        return self.model.forward(inp)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return SGD(self.parameters(),lr=learning_rate)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_sz = len(image_batch)\n",
    "        #label_batch = label_batch.to(DEVICE)\n",
    "        #image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28)\n",
    "        label_batch = label_batch\n",
    "        image_batch = image_batch.reshape(batch_sz, 1, 28, 28)\n",
    "        output = model(image_batch)\n",
    "        loss = nn.CrossEntropyLoss()(output, label_batch)\n",
    "\n",
    "        preds_train = torch.argmax(output, dim=1)\n",
    "        correct_train += int(torch.eq(preds_train,label_batch).sum())\n",
    "        minibatch_accuracy_train = 100*correct_train / batch_sz\n",
    "\n",
    "        self.log(\"train_acc\",minibatch_accuracy_train)\n",
    "        self.log(\"train_loss\",loss)\n",
    "\n",
    "        \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        image_batch,label_batch = batch\n",
    "        batch_sz = len(image_batch)\n",
    "        #label_batch = label_batch.to(DEVICE)\n",
    "        #image_batch = image_batch.to(DEVICE).reshape(batch_sz, 1, 28, 28)\n",
    "        label_batch = label_batch\n",
    "        image_batch = image_batch.reshape(batch_sz, 1, 28, 28)\n",
    "        output = model(image_batch)\n",
    "        loss = nn.CrossEntropyLoss()(output, label_batch)\n",
    "\n",
    "\n",
    "        preds_val = torch.argmax(output, dim=1)\n",
    "        correct_val += int(torch.eq(preds_val,label_batch).sum())\n",
    "        minibatch_accuracy_val = 100*correct_val / batch_sz\n",
    "\n",
    "        self.log(\"val_acc\",minibatch_accuracy_val)\n",
    "        self.log(\"val_loss\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cccfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_dl, val_dl, test_dl = load_data(DATA_PATH, batch_sz=batch_sz)\n",
    "\n",
    "# Instantiate PlResNet with the appropriate inputs and outputs\n",
    "model = PlResNet(in_channels=1,outputs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7eaa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fa2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "# saves last-K checkpoints based on \"global_step\" metric\n",
    "# make sure you log it inside your LightningModule\n",
    "# NOTE: Talk a little bit about what callback functions are\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=5,\n",
    "    monitor='val_loss',  # 'val_acc' or 'val_loss'\n",
    "    mode='min',           # one of {auto, min, max}\n",
    "    dirpath= './Saved_models',\n",
    "    filename= \"mnist_nodel_{epoch:02d}\"\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_acc\",\n",
    "    mode='max',\n",
    "    patience=3,\n",
    "    min_delta=0.0\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer(accelerator='gpu',\n",
    "                     devices=1,\n",
    "                     callbacks=[early_stop_callback,checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dl,val_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
